{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7a5079",
   "metadata": {},
   "source": [
    "Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Dependencies\n",
    "!pip install tensorflow\n",
    "!pip install matplotlib\n",
    "!pip install tqdm\n",
    "!pip install flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d966966",
   "metadata": {},
   "source": [
    "Extract Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd1c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Dataset Path\n",
    "DATASET = \"C:\\\\Users\\\\tejas\\\\Documents\\\\COLLEGE\\\\SEMESTER_5\\\\EDI_DeepFake_ImageDetection\\\\dataset.zip\"\n",
    "\n",
    "# Extract Dataset with Progress Bar\n",
    "import zipfile\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "# Replace \"/content/drive/MyDrive/deepfakeimgdetection/dataset.zip\" with the local path\n",
    "with zipfile.ZipFile(DATASET, 'r') as zip_ref:\n",
    "    # Get the total number of files in the zip archive for progress tracking\n",
    "    num_files = len(zip_ref.namelist())\n",
    "    \n",
    "    # Use tqdm to create a progress bar\n",
    "    with tqdm(total=num_files, desc='Extracting', unit=' files') as pbar:\n",
    "        for file in zip_ref.namelist():\n",
    "            zip_ref.extract(file, \"C:\\\\Users\\\\tejas\\\\Documents\\\\COLLEGE\\\\SEMESTER_5\\\\EDI_DeepFake_ImageDetection\")\n",
    "            pbar.update(1)  # Update progress bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cebe841",
   "metadata": {},
   "source": [
    "Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713cd78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Local Dataset Path\n",
    "data_dir = \"C:\\\\Users\\\\tejas\\\\Documents\\\\COLLEGE\\\\SEMESTER_5\\\\EDI_DeepFake_ImageDetection\\\\Dataset\"\n",
    "\n",
    "# Local subfolders\n",
    "subfolders = [\"Fake\", \"Real\"]\n",
    "\n",
    "def setup_directory_and_count_files(directory, subfolders):\n",
    "    total_files = 0\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(directory, subfolder)\n",
    "        total_files += sum([1 for file in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, file))])\n",
    "    return total_files\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"Train\")\n",
    "test_dir = os.path.join(data_dir, \"Test\")\n",
    "validation_dir = os.path.join(data_dir, \"Validation\")\n",
    "\n",
    "total_train_files = setup_directory_and_count_files(train_dir, subfolders)\n",
    "total_test_files = setup_directory_and_count_files(test_dir, subfolders)\n",
    "total_validation_files = setup_directory_and_count_files(validation_dir, subfolders)\n",
    "\n",
    "total = total_train_files + total_test_files + total_validation_files\n",
    "train_perc = (total_train_files / total) * 100\n",
    "test_perc = (total_test_files / total) * 100\n",
    "valid_perc = (total_validation_files / total) * 100\n",
    "print(\"Total Train Files:\", total_train_files)\n",
    "print(\"Total Test Files:\", total_test_files)\n",
    "print(\"Total Validation Files:\", total_validation_files)\n",
    "print(f\"Train Data Percentage: {train_perc:.2f}%\")\n",
    "print(f\"Test Data Percentage: {test_perc:.2f}%\")\n",
    "print(f\"Validation Data Percentage: {valid_perc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca183ec1",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "\n",
    "data_dir = \"C:\\\\Users\\\\tejas\\\\Documents\\\\COLLEGE\\\\SEMESTER_5\\\\EDI_DeepFake_ImageDetection\\\\Dataset\"  \n",
    "\n",
    "train_dir = os.path.join(data_dir, \"Train\")\n",
    "test_dir = os.path.join(data_dir, \"Test\")\n",
    "validation_dir = os.path.join(data_dir, \"Validation\")\n",
    "subfolders = [\"Fake\", \"Real\"]\n",
    "\n",
    "def normalize_image(image, labels):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, labels\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (256, 256)\n",
    "\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE\n",
    ").map(normalize_image).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "validation_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE\n",
    ").map(normalize_image).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=False\n",
    ").map(normalize_image).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "model_CNN = Sequential([\n",
    "    Conv2D(filters=8, kernel_size=3, padding='same', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "\n",
    "    Conv2D(filters=16, kernel_size=4, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=128, kernel_size=1, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    Flatten(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=20, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_CNN.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "epoch_num = 50  # Define the number of epochs\n",
    "hist = model_CNN.fit(train_data,\n",
    "                    epochs=epoch_num,\n",
    "                    validation_data=validation_data,\n",
    "                    validation_steps=int(0.5 * len(validation_data))\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527c93e",
   "metadata": {},
   "source": [
    "Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37495438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Save the Trained Model\n",
    "svpth = \"C:\\\\Users\\\\tejas\\\\Documents\\\\COLLEGE\\\\SEMESTER_5\\\\EDI_DeepFake_ImageDetection\\\\Model\"\n",
    "# @markdown Save Model As:\n",
    "model_name = \"dfimgdet50ep\" # @param {type:\"string\"}\n",
    "modelwext = model_name + \".h\"\n",
    "save_path = svpth + modelwext\n",
    "model_CNN.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735d17b",
   "metadata": {},
   "source": [
    "Load a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c74628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load a Model\n",
    "from tensorflow.keras.models import load_model\n",
    "# @markdown Model Path:\n",
    "model_path = \"C:\\\\Users\\\\tejas\\\\Documents\\\\COLLEGE\\\\SEMESTER_5\\\\EDI_DeepFake_ImageDetection\\\\Model\\\\model_checkpoint_33.h5\" # @param {type:\"string\"}\n",
    "loaded_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d7284",
   "metadata": {},
   "source": [
    "Test- Upload an Image (TKinter UI) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0acec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load your pre-trained model\n",
    "loaded_model = load_model('C:\\\\Users\\\\tejas\\\\Documents\\\\COLLEGE\\\\SEMESTER_5\\\\EDI_DeepFake_ImageDetection\\\\Model\\\\model_checkpoint_33.h5')  # Replace with the path to your model\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path, threshold=0.5):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(256, 256))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "\n",
    "    # Determine the classification result based on the threshold\n",
    "    if predictions[0][0] >= threshold:\n",
    "        result = \"The uploaded image is a deepfake.\"\n",
    "    else:\n",
    "        result = \"The uploaded image is not a deepfake.\"\n",
    "\n",
    "    return result\n",
    "\n",
    "# Function to handle file upload\n",
    "def upload_file():\n",
    "    file_path = filedialog.askopenfilename(title=\"Select an Image File\")\n",
    "    if file_path:\n",
    "        classification_result = classify_image(file_path, threshold=0.5)\n",
    "        result_label.config(text=classification_result)\n",
    "\n",
    "# Create a tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"Deepfake Image Classification\")\n",
    "\n",
    "# Create and configure a button for file upload\n",
    "upload_button = tk.Button(window, text=\"Upload Image\", command=upload_file)\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "# Create a label to display the classification result\n",
    "result_label = tk.Label(window, text=\"\", font=(\"Helvetica\", 16))\n",
    "result_label.pack()\n",
    "\n",
    "# Start the tkinter main loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb6184",
   "metadata": {},
   "source": [
    "Web-UI Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79a57f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Sep/2023 11:12:06] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Sep/2023 11:12:07] \"GET /style.css HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [06/Sep/2023 11:12:07] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Sep/2023 11:12:07] \"GET /img/bg.jpg HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [06/Sep/2023 11:12:07] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 422ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Sep/2023 11:12:14] \"POST /classify-image HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Sep/2023 11:12:19] \"POST /classify-image HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Sep/2023 11:12:25] \"POST /classify-image HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "app = Flask(__name__, template_folder='C:\\\\Users\\\\tejas\\\\Documents\\\\COLLEGE\\\\SEMESTER_5\\\\EDI_DeepFake_ImageDetection')\n",
    "\n",
    "# Set the upload folder and allowed extensions\n",
    "app.config['UPLOAD_FOLDER'] = 'C:\\\\Users\\\\tejas\\\\Documents\\\\COLLEGE\\\\SEMESTER_5\\\\EDI_DeepFake_ImageDetection\\\\upload'\n",
    "app.config['ALLOWED_EXTENSIONS'] = {'png', 'jpg', 'jpeg', 'gif'}\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']\n",
    "\n",
    "# Load your pre-trained model\n",
    "loaded_model = load_model('C:\\\\Users\\\\tejas\\\\Documents\\\\COLLEGE\\\\SEMESTER_5\\\\EDI_DeepFake_ImageDetection\\\\Model\\\\model_checkpoint_33.h5')  # Replace with the path to your model\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path, threshold=0.5):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(256, 256))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "\n",
    "    # Determine the classification result based on the threshold\n",
    "    if predictions[0][0] >= threshold:\n",
    "        result = \"The uploaded image is a DeepFake!\"\n",
    "    else:\n",
    "        result = \"The uploaded image is NOT a DeepFake!\"\n",
    "\n",
    "    return result\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/classify-image', methods=['POST'])\n",
    "def classify_image_api():\n",
    "    # Check if the post request has the file part\n",
    "    if 'file' not in request.files:\n",
    "        return 'No file part'\n",
    "    file = request.files['file']\n",
    "    # If the user does not select a file, the browser submits an\n",
    "    # empty file without a filename.\n",
    "    if file.filename == '':\n",
    "        return 'No selected file'\n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = secure_filename(file.filename)\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(file_path)\n",
    "        classification_result = classify_image(file_path, threshold=0.5)\n",
    "        return classification_result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
